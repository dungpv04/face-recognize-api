import os
from fastapi import UploadFile
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

from typing import List
import pandas as pd
import numpy as np
import faiss
import cv2 as cv
from mtcnn import MTCNN
from keras_facenet import FaceNet
from fastapi import HTTPException
from sqlmodel import Session, select
from face_recoginze_api.database.tables import FaceEmbeddingModel, FaceVector
from sqlmodel.ext.asyncio.session import AsyncSession
from enum import Enum
import tempfile
import shutil


class ErrorType(Enum):
    NO_FACE_DETECED = "No face detected"
    FACE_NOT_FOUND = "Face not found"
    NOT_MOVING_FACE = "Not a moving face"
    INTERNAL_SERVER_ERROR = "Internal server error"
    USERNAME_EXISTED = "Username has already exist in database"
    FACE_EXISTED = "One or more of the images contains a face that has already exist in database"

class FaceRecognizeService:

    async def initialize(self, db_session: AsyncSession):

        self.detector = MTCNN()
        self.facenet = FaceNet()
        # Truy v·∫•n d·ªØ li·ªáu t·ª´ c·∫£ hai b·∫£ng b·∫±ng JOIN
        result = await db_session.execute(
            select(FaceEmbeddingModel.label, FaceVector.vector)
            .join(FaceVector, FaceVector.face_embedding_id == FaceEmbeddingModel.id)
        )
        embeddings = result.all()  # L·∫•y t·∫•t c·∫£ k·∫øt qu·∫£
        if len(embeddings) == 0:
            return
        else:
        # Chuy·ªÉn d·ªØ li·ªáu v·ªÅ NumPy Array
            self.labels = np.array([e[0] for e in embeddings])  
            self.vectors = np.array([np.array(e[1], dtype=np.float32) for e in embeddings])

            # √Ånh x·∫° ch·ªâ s·ªë FAISS -> t√™n ng∆∞·ªùi
            self.index_to_name = {i: name for i, name in enumerate(self.labels)}

            # Kh·ªüi t·∫°o FAISS Index
            dimension = self.vectors.shape[1]
            self.index = faiss.IndexHNSWFlat(dimension, 32)  # Faster Approximate Search
            self.index.add(self.vectors)

    
    def recognize_face_faiss(self, face_vector, top_k=5, threshold=1.0):
        """
        T√¨m ng∆∞·ªùi g·∫ßn nh·∫•t v·ªõi face_vector b·∫±ng FAISS.
        N·∫øu kho·∫£ng c√°ch > threshold, tr·∫£ v·ªÅ 'Unknown'.
        """
        face_vector = np.array(face_vector).astype('float32').reshape(1, -1)
        D, I = self.index.search(face_vector, top_k)
        
        best_index = I[0][0]
        best_distance = D[0][0]
        
        if best_distance > threshold:
            return None, None
        
        return self.index_to_name[best_index], best_distance
    
    async def generate_face_embeddings_sample(self, db_session: AsyncSession, dataset_path="src\dataset"):
        try:
            if db_session is None:
                raise ValueError("‚ö†Ô∏è C·∫ßn cung c·∫•p db_session ƒë·ªÉ k·∫øt n·ªëi database!")

            num_folders = 0
            num_files = 0

            for root, dirs, files in os.walk(dataset_path):
                num_folders += len(dirs)
                num_files += len(files)

            print(f"{num_files} and {num_folders}")

            for root, dirs, files in os.walk(dataset_path):
                label = os.path.basename(root)
                print(f"üìÇ ƒê·ªçc th∆∞ m·ª•c: {label}")
                count = 1

                # Ki·ªÉm tra xem ng∆∞·ªùi d√πng ƒë√£ t·ªìn t·∫°i ch∆∞a
                statement = select(FaceEmbeddingModel).where(FaceEmbeddingModel.label == label)
                with await db_session.execute(statement) as result:
                    face = result.scalars().first()

                if face:
                    face_embedding_id = face.id
                else:
                    new_face = FaceEmbeddingModel(label=label)
                    db_session.add(new_face)
                    await db_session.flush()  
                    face_embedding_id = new_face.id

                for file in files:
                    file_path = os.path.join(root, file)
                    print(f"  üìÑ X·ª≠ l√Ω: {file_path}")

                    img_bgr = cv.imread(file_path)
                    if img_bgr is None:
                        print(f"‚ö†Ô∏è L·ªói ƒë·ªçc ·∫£nh: {file_path}")
                        continue

                    img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)
                    results = self.detector.detect_faces(img_rgb)

                    if results:
                        x, y, w, h = results[0]['box']
                        face_img = img_rgb[y:y+h, x:x+w]

                        if face_img.shape[0] > 0 and face_img.shape[1] > 0:
                            face_img = cv.resize(face_img, (160, 160))
                            face_img = np.expand_dims(face_img, axis=0)

                            # L·∫•y embeddings
                            ypred = self.facenet.embeddings(face_img).flatten().tolist()
                            print(f"üéØ Embedding t·∫°o th√†nh c√¥ng: {ypred[:5]}...")  # Debug

                            # L∆∞u v√†o DB
                            new_vector = FaceVector(vector=ypred, face_embedding_id=face_embedding_id)
                            db_session.add(new_vector)
                            print(f"üìù ƒê√£ th√™m vector v√†o DB: {new_vector}")
                        if count == 5:
                            break
                        count += 1

            await db_session.commit()  
            return "‚úÖ ƒê√£ commit d·ªØ li·ªáu v√†o PostgreSQL th√†nh c√¥ng!"
        except Exception as e:
            print(e)
            return ErrorType.INTERNAL_SERVER_ERROR.value


    
    def recognize_face(self, file: UploadFile):
        # if not self.validate_face(file):
        #     return ErrorType.NOT_MOVING_FACE.value

        frame = self.read_image(file)
        frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)  # Chuy·ªÉn BGR ‚Üí RGB
        results = self.detector.detect_faces(frame_rgb)
        
        if results:
            print(results)
            x, y, w, h = results[0]['box']
            face_img = frame[y: y+h, x: x+w]
            face_img = cv.resize(face_img, (160, 160))
            face_img = np.expand_dims(face_img, axis=0)
            embedding = self.facenet.embeddings(face_img)
            predicted_name, confidence = self.recognize_face_faiss(embedding)
            if predicted_name:
                return predicted_name
            return ErrorType.FACE_NOT_FOUND.value
        return ErrorType.NO_FACE_DETECED.value
        

    def read_image(self, file: UploadFile):
        
        file_bytes = np.frombuffer(file.file.read(), np.uint8)
        frame = cv.imdecode(file_bytes, cv.IMREAD_COLOR)

        if frame is None:
            raise HTTPException(status_code=500, detail="An error occur while trying to read image.")

        return frame
    
    def read_video(self, file: UploadFile):
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
            temp_video.write(file.file.read())
            return temp_video.name
    
    def save_files_to_temp(self, files: List[UploadFile]) -> List[str]:
        temp_dir = tempfile.mkdtemp()  # T·∫°o th∆∞ m·ª•c t·∫°m th·ªùi
        saved_paths = []
        
        for file in files:
            file_path = f"{temp_dir}/{file.filename}"
            with open(file_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)  # Ghi file v√†o th∆∞ m·ª•c temp
            saved_paths.append(file_path)

        return saved_paths  # Tr·∫£ v·ªÅ danh s√°ch file ƒë√£ l∆∞u

    async def generate_face_embeddings(self, username, files: List[UploadFile], db_session: AsyncSession):
        try:
            if db_session is None:
                return ErrorType.INTERNAL_SERVER_ERROR.value

            #save_paths: List[str] = self.save_files_to_temp(files)
            statement = select(FaceEmbeddingModel).where(FaceEmbeddingModel.label == username)
            with await db_session.execute(statement) as result:
                face = result.first()
                if face:
                    await db_session.rollback()
                    return ErrorType.USERNAME_EXISTED.value
                new_face = FaceEmbeddingModel(label=username)
                db_session.add(new_face)
                await db_session.flush()
                print(f"Adding: {new_face.model_dump()}")
                face_embedding_id = new_face.id
            print(f"üìÇ T·ªïng s·ªë file c·∫ßn x·ª≠ l√Ω: {len(files)}")
            new_vectors: list[FaceVector] = []
            new_embeddings = []
            for save_path in files:
                # Ki·ªÉm tra xem ng∆∞·ªùi d√πng ƒë√£ t·ªìn t·∫°i ch∆∞a
                # ƒê·ªçc ·∫£nh
                img_bgr = self.read_image(save_path)
                if img_bgr is None:
                    raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh")

                img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)
                results = self.detector.detect_faces(img_rgb)

                if not results:
                    raise ValueError("Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t")

                x, y, w, h = results[0]['box']
                face_img = img_rgb[y:y+h, x:x+w]

                if face_img.shape[0] <= 0 or face_img.shape[1] <= 0:
                    raise ValueError("·∫¢nh kh√¥ng h·ª£p l·ªá sau khi crop")

                face_img = cv.resize(face_img, (160, 160))
                face_img = np.expand_dims(face_img, axis=0)

                ypred = self.facenet.embeddings(face_img).flatten().tolist()
                is_face_in_db, _ = self.recognize_face_faiss(ypred)
                if is_face_in_db:
                    await db_session.rollback()
                    return ErrorType.FACE_EXISTED.value
                print(f"üéØ Embedding t·∫°o th√†nh c√¥ng: {ypred[:5]}...")

                new_vector = FaceVector(vector=ypred, face_embedding_id=face_embedding_id)
                new_vectors.append(new_vector)
                new_embeddings.append(ypred)
                print(f"üìù ƒê√£ th√™m vector v√†o DB: {new_vector}")

            db_session.add_all(new_vectors)
            
            await db_session.commit()
            if new_embeddings:
                new_embeddings_np = np.array(new_embeddings, dtype=np.float32)
                start_index = self.index.ntotal  # L·∫•y index b·∫Øt ƒë·∫ßu t·ª´ FAISS

                self.index.add(new_embeddings_np)  # Th√™m vector m·ªõi v√†o FAISS

                # C·∫≠p nh·∫≠t index_to_name v·ªõi m·ªôt nh√£n duy nh·∫•t (username)
                for i in range(len(new_embeddings)):
                    self.index_to_name[start_index + i] = username
            return "Face has been added to database."

        except Exception as e:
            print(f"‚ùå L·ªñI: {e}")
            await db_session.rollback()
            return ErrorType.INTERNAL_SERVER_ERROR.value
        
    # def validate_face(self, file: UploadFile):
    #     vertical_move = False
    #     horizontal_move = False
    #     cap = cv.VideoCapture(self.read_video(file))
    #     while cap.isOpened():
    #         ret, frame = cap.read()
    #         frame = cv.flip(frame, 1)
    #         if not ret:
    #             break

    #         # Chuy·ªÉn ·∫£nh sang RGB (MTCNN y√™u c·∫ßu ƒë·ªãnh d·∫°ng n√†y)
    #         rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)

    #         # Ph√°t hi·ªán khu√¥n m·∫∑t
    #         faces = self.detector.detect_faces(rgb_frame)
    #         prev_keypoints = None
    #         if faces:
    #             for face in faces:
    #                 keypoints = face["keypoints"]

    #                 # L·∫•y v·ªã tr√≠ m·∫Øt v√† m≈©i
    #                 left_eye = np.array(keypoints["left_eye"])
    #                 right_eye = np.array(keypoints["right_eye"])
    #                 nose = np.array(keypoints["nose"])

    #                 # V·∫Ω keypoints l√™n ·∫£nh
    #                 x, y, width, height = face["box"]
    #                 cv.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)

    #                 # N·∫øu ƒë√£ c√≥ frame tr∆∞·ªõc, so s√°nh v·ªã tr√≠ ƒë·ªÉ x√°c ƒë·ªãnh h∆∞·ªõng di chuy·ªÉn
    #                 if prev_keypoints is not None:
    #                     prev_nose = prev_keypoints["nose"]

    #                     movement = nose - prev_nose
    #                     direction = ""

    #                     if movement[0] > 5:
    #                         direction = "Right ‚Üí"
    #                         horizontal_move = True
    #                     elif movement[0] < -5:
    #                         direction = "‚Üê Left"
    #                         horizontal_move = True

    #                     if movement[1] > 5:
    #                         direction += " ‚Üì Down"
    #                         vertical_move = True
    #                     elif movement[1] < -5:
    #                         direction += " ‚Üë Up"
    #                         vertical_move = True

    #                     # Hi·ªÉn th·ªã h∆∞·ªõng di chuy·ªÉn l√™n m√†n h√¨nh
    #                     print(f"Direction: {direction}")

    #                     left_eye = keypoints['left_eye']
    #                     right_eye = keypoints['right_eye']

    #                 # C·∫≠p nh·∫≠t keypoints c·ªßa frame tr∆∞·ªõc
    #                 prev_keypoints = keypoints
    #     return vertical_move and horizontal_move

